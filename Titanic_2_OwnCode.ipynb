{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cross_validation import KFold #cross_val_score         # DHANK - This import option may be changed \n",
    "from sklearn.model_selection import cross_val_score                 # DHANK - This import option may be changed \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re                                                          # Reg-ex for Family Names Mr etc \n",
    "import operator\n",
    "# Data Quest Type Analysis stops---- \n",
    "#\n",
    "# Basis info here -SPLITTER CLASSES - http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\n",
    "# looking at various SPLITTER Options \n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "# My GitHubRepo - https://github.com/RohitDhankar\n",
    "# Kaggle Profile - https://www.kaggle.com/rohitdhankar\n",
    "\n",
    "# Python 3.5 Notebook to be uploaded to Kaggle - Python 3.5 virtual env activated - usually work with 2.7 \n",
    "#\n",
    "#conda create -n py35 python=3.5 ipykernel\n",
    "#source activate py35\n",
    "#\n",
    "# conda create -n py27 python=2.7 ipykernel\n",
    "# source activate py27\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import mixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 891, Number of columns: 12\n",
      "__________________________________________________________________________________________\n",
      "Number of rows: 418, Number of columns: 11\n",
      "__________________________________________________________________________________________\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "__________________________________________________________________________________________\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "dfTrn = pd.read_csv(\"train.csv\") # On Local Machine \n",
    "dfTest = pd.read_csv(\"test.csv\") # On Local Machine \n",
    "#dfTrn = pd.read_csv(\"../input/train.csv\") # On Kaggle \n",
    "#dfTest = pd.read_csv(\"../input/test.csv\") # On Kaggle \n",
    "print('Number of rows: {}, Number of columns: {}'.format(*dfTrn.shape))\n",
    "print (\"_\"*90)\n",
    "print('Number of rows: {}, Number of columns: {}'.format(*dfTest.shape))\n",
    "print (\"_\"*90)\n",
    "print(dfTrn.head(5))\n",
    "print (\"_\"*90)\n",
    "print(dfTest.head(5))\n",
    "\n",
    "# If any Encoding or Mapping of String values in Features with Categorical or Numeric is required use MAP \n",
    "# MAP being own function it replaces in place and not creating another feature like One Hot Encoder etc \n",
    "# For Titanic this is not required \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId = 0\n",
      "Survived = 0\n",
      "Pclass = 0\n",
      "Name = 0\n",
      "Sex = 0\n",
      "Age = 177\n",
      "SibSp = 0\n",
      "Parch = 0\n",
      "Ticket = 0\n",
      "Fare = 0\n",
      "Cabin = 687\n",
      "Embarked = 2\n"
     ]
    }
   ],
   "source": [
    "feature_labels = []\n",
    "missing_values = []\n",
    "\n",
    "for col in dfTrn.columns:\n",
    "    feature_labels.append(col)\n",
    "    missing_values.append(dfTrn[col].isnull().values.ravel().sum()) # Append Feature wise Missing Values  \n",
    "    print(col,\"=\", missing_values[-1]) # prints Feature Labels with Missing Values Count ...\n",
    "\n",
    "#Source - http://stackoverflow.com/questions/28199524/best-way-to-count-the-number-of-rows-with-missing-values-in-a-pandas-dataframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Source - Kaggle - https://www.kaggle.com/michielkalkman/titanic/kaggle-titanic-001\n",
    "# This source is similar in approach and code to DataQuest.io - Titanic Tute \n",
    "# All code below is standard DataQuest.io code -\n",
    "\n",
    "# What happens to NA values in - CABIN ?? Seems no one has bothered Impute NA's of CABIN \n",
    "# as no one has used CABIN for Preds  -- CHECK further ....\n",
    "# EMBARK also dropped after checking BestFit [ skLearn . SelectKBest ] or RandomForest Feature Imp ? \n",
    "\n",
    "\n",
    "# df_Any is any data_set TRAIN or TEST passed to this function\n",
    "def harmonize_data(df_Any):\n",
    "    \n",
    "    df_Any[\"Age\"] = df_Any[\"Age\"].fillna(df_Any[\"Age\"].median()) # Missing Imputed with Median values\n",
    "#    \n",
    "    df_Any.loc[df_Any[\"Sex\"] == \"male\", \"Sex\"] = 0     # SWAP this is and check performance\n",
    "    df_Any.loc[df_Any[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "#    \n",
    "    df_Any[\"Embarked\"] = df_Any[\"Embarked\"].fillna(\"S\") # Impute missing values\n",
    "#\n",
    "    df_Any.loc[df_Any[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    df_Any.loc[df_Any[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    df_Any.loc[df_Any[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "    df_Any[\"Fare\"] = df_Any[\"Fare\"].fillna(df_Any[\"Fare\"].median())\n",
    "\n",
    "    return df_Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
      "5                                   Moran, Mr. James   0  28.0      0      0   \n",
      "6                            McCarthy, Mr. Timothy J   0  54.0      0      0   \n",
      "7                     Palsson, Master. Gosta Leonard   0   2.0      3      1   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   1  27.0      0      2   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)   1  14.0      1      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        0  \n",
      "1          PC 17599  71.2833   C85        1  \n",
      "2  STON/O2. 3101282   7.9250   NaN        0  \n",
      "3            113803  53.1000  C123        0  \n",
      "4            373450   8.0500   NaN        0  \n",
      "5            330877   8.4583   NaN        2  \n",
      "6             17463  51.8625   E46        0  \n",
      "7            349909  21.0750   NaN        0  \n",
      "8            347742  11.1333   NaN        0  \n",
      "9            237736  30.0708   NaN        1  \n",
      "__________________________________________________________________________________________\n",
      "   PassengerId  Pclass                                          Name Sex  \\\n",
      "0          892       3                              Kelly, Mr. James   0   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)   1   \n",
      "2          894       2                     Myles, Mr. Thomas Francis   0   \n",
      "3          895       3                              Wirz, Mr. Albert   0   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   1   \n",
      "5          897       3                    Svensson, Mr. Johan Cervin   0   \n",
      "6          898       3                          Connolly, Miss. Kate   1   \n",
      "7          899       2                  Caldwell, Mr. Albert Francis   0   \n",
      "8          900       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)   1   \n",
      "9          901       3                       Davies, Mr. John Samuel   0   \n",
      "\n",
      "    Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0     330911   7.8292   NaN        2  \n",
      "1  47.0      1      0     363272   7.0000   NaN        0  \n",
      "2  62.0      0      0     240276   9.6875   NaN        2  \n",
      "3  27.0      0      0     315154   8.6625   NaN        0  \n",
      "4  22.0      1      1    3101298  12.2875   NaN        0  \n",
      "5  14.0      0      0       7538   9.2250   NaN        0  \n",
      "6  30.0      0      0     330972   7.6292   NaN        2  \n",
      "7  26.0      1      1     248738  29.0000   NaN        0  \n",
      "8  18.0      0      0       2657   7.2292   NaN        1  \n",
      "9  21.0      2      0  A/4 48871  24.1500   NaN        0  \n",
      "__________________________________________________________________________________________\n",
      "['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Get Harmonized DF's from Train and Test Data \n",
    "# Cant be running this code cell or function more than once for a particular - df_Any # Test or Train \n",
    "\n",
    "df_harmonized_train = harmonize_data(dfTrn)\n",
    "print(df_harmonized_train.head(10))\n",
    "\n",
    "print (\"_\"*90)\n",
    "df_harmonized_test = harmonize_data(dfTest)\n",
    "print(df_harmonized_test.head(10))\n",
    "\n",
    "names = df_harmonized_test.columns.values\n",
    "print (\"_\"*90)\n",
    "print (names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.188908\n",
       "Sex[T.1]     0.553130\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Laterz Hold --- 07 JAN 17 \n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# create a fitted model in one line\n",
    "#lm = smf.ols(formula='Survived ~ Fare', data=df_harmonized_train).fit()\n",
    "lm = smf.ols(formula='Survived ~ Sex', data=df_harmonized_train).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.455068\n",
       "Age         -0.002426\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Laterz Hold --- 07 JAN 17 \n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# create a fitted model in one line\n",
    "#lm = smf.ols(formula='Survived ~ Fare', data=df_harmonized_train).fit()\n",
    "#lm = smf.ols(formula='Survived ~ Sex', data=df_harmonized_train).fit()\n",
    "lm = smf.ols(formula='Survived ~ Age', data=df_harmonized_train).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.91%\n"
     ]
    }
   ],
   "source": [
    "# Laterz Hold --- 07 JAN 17 \n",
    "\n",
    "#lm = smf.ols(formula='Survived ~ Fare', data=df_harmonized_train).fit()\n",
    "#Example for prediction (Fare == 70)\n",
    "\n",
    "B0 = Intrcpt_Beta0 = 0.302699\n",
    "B1 = Intrcpt_Beta1 = 0.002520 # Where B1 - Beta 1 - is coefficient of the feature f\n",
    "FObs = Feature_Obs = 70 \n",
    "\n",
    "print(\"{0:.2f}%\".format((B0 + B1*FObs) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890.80%\n"
     ]
    }
   ],
   "source": [
    "# Laterz Hold --- 07 JAN 17 \n",
    "\n",
    "#lm = smf.ols(formula='Survived ~ Sex', data=df_harmonized_train).fit()\n",
    "#Example for prediction (Fare == 70)\n",
    "\n",
    "B0 = Intrcpt_Beta0 = 0.188908\n",
    "B1 = Intrcpt_Beta1 = 0.553130 # Where B1 - Beta 1 - is coefficient of the feature f\n",
    "FObs = Feature_Obs = 70 \n",
    "\n",
    "print(\"{0:.2f}%\".format((B0 + B1*FObs) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.52%\n"
     ]
    }
   ],
   "source": [
    "# Laterz Hold --- 07 JAN 17 \n",
    "\n",
    "#lm = smf.ols(formula='Survived ~ Age', data=df_harmonized_train).fit()\n",
    "#Example for prediction (Fare == 70)\n",
    "\n",
    "B0 = Intrcpt_Beta0 = 0.455068\n",
    "B1 = Intrcpt_Beta1 = -0.002426 # Where B1 - Beta 1 - is coefficient of the feature f\n",
    "FObs = Feature_Obs = 70 \n",
    "\n",
    "print(\"{0:.2f}%\".format((B0 + B1*FObs) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn import cross_validation    # Depreciation Warning \n",
    "from sklearn.model_selection import cross_val_score # in place of \"cross_validation\" try \"model_selection\" \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "alg    = LogisticRegression(random_state=1)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    alg,\n",
    "    df_harmonized_train[predictors],\n",
    "    df_harmonized_train[\"Survived\"],\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "print(\"{0:.2f}%\".format(scores.mean() * 100))\n",
    "\n",
    "# Check how \"predictors\" can be \"names\" from above - not to to be typed manually \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score    # in place of \"cross_validation\" try \"model_selection\" \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"] #> 0.835056689342\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\",\"SibSp\"] #> 0.0.835034013605\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"] #> 0.842857142857 = 84.29% \n",
    "\n",
    "\n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 1 , 123 , 124\n",
    "    n_estimators=250,               # 150 , 250 , \n",
    "    min_samples_split=6,            # 4 , 6  \n",
    "    min_samples_leaf=2              # 2 , 2\n",
    ")\n",
    "                              \n",
    "\n",
    "scores = cross_val_score(\n",
    "    alg,                           # ALGORITHM in Cross_val_score Documentation is called - ESTIMATOR\n",
    "    df_harmonized_train[predictors], # X Array like INDEPENDENT VARIABLES \n",
    "    df_harmonized_train[\"Survived\"], # y Array like TARGET or DEPENDENT VARIABLE\n",
    "    cv=18                            # Default = 3 Fold Cross Validation , we used - 5 , 15, 18 \n",
    ")\n",
    "\n",
    "print(\"{0:.2f}%\".format(scores.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  FamilySize  \n",
       "0         A/5 21171   7.2500   NaN        0           1  \n",
       "1          PC 17599  71.2833   C85        1           1  \n",
       "2  STON/O2. 3101282   7.9250   NaN        0           0  \n",
       "3            113803  53.1000  C123        0           1  \n",
       "4            373450   8.0500   NaN        0           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# within the df_harmonized_train - which is our TRAIN DF of INDEPENDENT FEATURES \n",
    "# Add a FEATURE called - FamilySize\n",
    "\n",
    "df_harmonized_train[\"FamilySize\"] = df_harmonized_train[\"SibSp\"] + df_harmonized_train[\"Parch\"]\n",
    "#df_harmonized_train[\"NameLength\"] = df_harmonized_train[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "df_harmonized_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Major         2\n",
      "Col           2\n",
      "Mlle          2\n",
      "Jonkheer      1\n",
      "Don           1\n",
      "Lady          1\n",
      "Countess      1\n",
      "Sir           1\n",
      "Ms            1\n",
      "Mme           1\n",
      "Capt          1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilyId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  FamilySize Title  FamilyId  \n",
       "0         A/5 21171   7.2500   NaN        0           1     1        -1  \n",
       "1          PC 17599  71.2833   C85        1           1     3        -1  \n",
       "2  STON/O2. 3101282   7.9250   NaN        0           0     2        -1  \n",
       "3            113803  53.1000  C123        0           1     3        -1  \n",
       "4            373450   8.0500   NaN        0           0     1        -1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a FUNC \"get_title\" - use Reg-Ex to get the Titles \n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Apply .apply - above function to df_TRAIN --- same done to df_TEST below in another code cell \n",
    "\n",
    "titles = df_harmonized_train[\"Name\"].apply(get_title)\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "# Prints out the Titles available in df_TRAIN these are different for df_TEST \n",
    "# We create - title_mapping , below basis this above print out - print(pd.value_counts(titles))\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \n",
    "                 \"Major\": 7, \"Col\": 7, \"Capt\": 7,\n",
    "                 \"Mlle\": 8, \"Mme\": 8, \n",
    "                 \"Don\": 9, \n",
    "                 \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \n",
    "                 \"Sir\": 9, \n",
    "                 \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "print(pd.value_counts(titles))\n",
    "\n",
    "df_harmonized_train[\"Title\"] = titles   # Add a Feature called - \"Title\"\n",
    "df_harmonized_train.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1      800\n",
      " 14       8\n",
      " 149      7\n",
      " 63       6\n",
      " 50       6\n",
      " 59       6\n",
      " 17       5\n",
      " 384      4\n",
      " 27       4\n",
      " 25       4\n",
      " 162      4\n",
      " 8        4\n",
      " 84       4\n",
      " 340      4\n",
      " 43       3\n",
      " 269      3\n",
      " 58       3\n",
      " 633      2\n",
      " 167      2\n",
      " 280      2\n",
      " 510      2\n",
      " 90       2\n",
      " 83       1\n",
      " 625      1\n",
      " 376      1\n",
      " 449      1\n",
      " 498      1\n",
      " 588      1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilyId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  FamilySize Title  FamilyId  \n",
       "0         A/5 21171   7.2500   NaN        0           1     1        -1  \n",
       "1          PC 17599  71.2833   C85        1           1     3        -1  \n",
       "2  STON/O2. 3101282   7.9250   NaN        0           0     2        -1  \n",
       "3            113803  53.1000  C123        0           1     3        -1  \n",
       "4            373450   8.0500   NaN        0           0     1        -1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_id_mapping = {} # Instantiate empty Dict \n",
    "\n",
    "def get_family_id(row):\n",
    "    last_name = row[\"Name\"].split(\",\")[0]   # In values of feature \"Name\" (\",\") separates LASTNAME from other Names\n",
    "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
    "    if family_id not in family_id_mapping:\n",
    "        if len(family_id_mapping) == 0:\n",
    "            current_id = 1\n",
    "        else:\n",
    "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
    "        family_id_mapping[family_id] = current_id\n",
    "    return family_id_mapping[family_id]\n",
    "\n",
    "family_ids = df_harmonized_train.apply(get_family_id, axis=1)  #Create PD_Core_Series traverse Axis=1-ROWS_Top_down \n",
    "\n",
    "family_ids[df_harmonized_train[\"FamilySize\"] < 3] = -1             # All FamilySize's < 3 give default ID(-1)\n",
    "\n",
    "print(pd.value_counts(family_ids))\n",
    "\n",
    "\n",
    "df_harmonized_train[\"FamilyId\"] = family_ids                       # Add a Feature - \"FamilyId\"\n",
    "df_harmonized_train.head(5)\n",
    "#print(type(family_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 15)\n",
      "(223, 15)\n",
      "(668,)\n",
      "(223,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilyId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mionoff, Mr. Stoytcho</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349207</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Erna Alexandra</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3101281</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lobb, Mr. William Arthur</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 3336</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dennis, Mr. Samuel</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21172</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>707</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Kelly, Mrs. Florence \"Fannie\"</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223596</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                             Name Sex   Age  \\\n",
       "105          106         0       3            Mionoff, Mr. Stoytcho   0  28.0   \n",
       "68            69         1       3  Andersson, Miss. Erna Alexandra   1  17.0   \n",
       "253          254         0       3         Lobb, Mr. William Arthur   0  30.0   \n",
       "320          321         0       3               Dennis, Mr. Samuel   0  22.0   \n",
       "706          707         1       2    Kelly, Mrs. Florence \"Fannie\"   1  45.0   \n",
       "\n",
       "     SibSp  Parch     Ticket     Fare Cabin Embarked  FamilySize Title  \\\n",
       "105      0      0     349207   7.8958   NaN        0           0     1   \n",
       "68       4      2    3101281   7.9250   NaN        0           6     2   \n",
       "253      1      0  A/5. 3336  16.1000   NaN        0           1     1   \n",
       "320      0      0  A/5 21172   7.2500   NaN        0           0     1   \n",
       "706      0      0     223596  13.5000   NaN        0           0     3   \n",
       "\n",
       "     FamilyId  \n",
       "105        -1  \n",
       "68         14  \n",
       "253        -1  \n",
       "320        -1  \n",
       "706        -1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df_harmonized_train,df_harmonized_train['Survived'], test_size=0.25, random_state=0)\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DHNAK--  Hold - 7th JAN \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, \n",
    "# and everything with the gradient boosting classifier.\n",
    "\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), np.append(np.append([\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"S\",\"C\",\"Q\",\"FamilySize\", \"FamilyId\"],cabin_values), title_values)],\n",
    "    [LogisticRegression(random_state=1), np.append(np.append([\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\",\"Age\",\"S\",\"C\",\"Q\"],cabin_values),title_values)]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(xtrain.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = ytrain.iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(xtrain[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(xtrain[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions == ytrain) / float(len(predictions))\n",
    "print(accuracy)\n",
    "sum(predictions==ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Rev         2\n",
      "Col         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "Dona        1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a FUNC \"get_title\" - use Reg-Ex to get the Titles \n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Apply .apply - above function to df_TRAIN --- same done to df_TEST below in another code cell \n",
    "\n",
    "titles_testDF = df_harmonized_test[\"Name\"].apply(get_title)\n",
    "print(pd.value_counts(titles_testDF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    240\n",
      "2     78\n",
      "3     72\n",
      "4     21\n",
      "7      2\n",
      "6      2\n",
      "9      1\n",
      "8      1\n",
      "5      1\n",
      "Name: Name, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                          Name Sex   Age  SibSp  \\\n",
       "413         1305       3            Spector, Mr. Woolf   0  27.0      0   \n",
       "414         1306       1  Oliva y Ocana, Dona. Fermina   1  39.0      0   \n",
       "415         1307       3  Saether, Mr. Simon Sivertsen   0  38.5      0   \n",
       "416         1308       3           Ware, Mr. Frederick   0  27.0      0   \n",
       "417         1309       3      Peter, Master. Michael J   0  27.0      1   \n",
       "\n",
       "     Parch              Ticket      Fare Cabin Embarked Title  \n",
       "413      0           A.5. 3236    8.0500   NaN        0     1  \n",
       "414      0            PC 17758  108.9000  C105        1     8  \n",
       "415      0  SOTON/O.Q. 3101262    7.2500   NaN        0     1  \n",
       "416      0              359309    8.0500   NaN        0     1  \n",
       "417      1                2668   22.3583   NaN        1     4  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Above Code Cell -  Prints out Titles available in df_Test these are different for df_TRAIN - DONA  \n",
    "# We create - title_mapping , below basis this above print out - print(pd.value_counts(titles))\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6,\"Col\": 7,\"Dona\":8,\"Ms\": 9}\n",
    "\n",
    "for k,v in title_mapping.items():\n",
    "    titles_testDF[titles_testDF == k] = v\n",
    "\n",
    "print(pd.value_counts(titles_testDF))\n",
    "\n",
    "df_harmonized_test[\"Title\"] = titles_testDF   # Add a Feature called - \"Title\"\n",
    "df_harmonized_test.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold and Check again -- Not sure why hes doing this ?? \n",
    "# Source - Git - https://github.com/adriannr/Kaggle/blob/400597bff03d2d791a2c4643b4b081af1fe42818/Titanic%20Kaggle%20Dataquest.ipynb\n",
    "# His Cell In [1335]\n",
    "\n",
    "\n",
    "col_to_add = np.setdiff1d(titanic.columns, titanic_test.columns)\n",
    "for c in col_to_add:\n",
    "    titanic_test[c] = 0\n",
    "titanic_test = titanic_test[titanic.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAGeCAYAAAB1m2N/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94694fb390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif , SelectFpr , chi2\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "selector = SelectKBest(f_classif, k=5) # OK Gives -- predictors = [\"Pclass\", \"Sex\", \"Title\", \"Fare\"] \n",
    "\n",
    "# Trying other Methods ------\n",
    "#selector = SelectKBest(SelectFpr, k=5) #AttributeError: 'NoneType' object has no attribute 'log10'\n",
    "#\n",
    "#\n",
    "#selector = SelectKBest(chi2, k=5) # Error --- \n",
    "# ValueError: Input X must be non-negative.\n",
    "# Googled --  sklearn.feature_selection chi2 ValueError: Input X must be non-negative. \n",
    "# http://stackoverflow.com/questions/25792012/feature-selection-using-scikit-learn\n",
    "\n",
    "\n",
    "selector.fit(df_harmonized_train[predictors], df_harmonized_train[\"Survived\"])\n",
    "\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score    # in place of \"cross_validation\" try \"model_selection\" \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"] #> 0.835056689342\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\",\"SibSp\"] #> 0.0.835034013605\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Title\", \"Fare\"] #> 83.61% # As suggested by - SelectKBest - Score Dropped ?? \n",
    "#predictors = [\"Pclass\", \"Sex\", \"Title\", \"Age\",\"Fare\",\"SibSp\"] #> 83.96%\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"] #> 0.842857142857 = 84.29% \n",
    "#predictors = [\"Pclass\", \"Sex\", \"Title\", \"Age\",\"Fare\",\"SibSp\"] #> 83.85%  ---- 7 JAN 17 \n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Title\", \"Age\",\"Fare\"] #> 84.75%  ---- 7 JAN 17 \n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 1 , 123 , 124 \n",
    "    n_estimators=350,               # 350 #> 84.74% , 650 #>84.63%    \n",
    "    max_features=2,                 # 2 Dont Change 2 is IDEAL , \n",
    "    min_samples_split=6,            # 4 , 6  # The Deafult Val = 2\n",
    "    min_samples_leaf=2,             # 2 , if 4 #> 83.95%\n",
    "    verbose=0                       # Make it 1 for print in console \n",
    ")\n",
    "\n",
    "                              \n",
    "#kFold = KFold(df_harmonized_train.shape[0], random_state=124, n_folds=10)\n",
    "#print(kFold)\n",
    "#print(\"_\"*90)\n",
    "\n",
    "\n",
    "scores = cross_val_score(\n",
    "    alg,                           # ALGORITHM in Cross_val_score Documentation is called - ESTIMATOR\n",
    "    df_harmonized_train[predictors], # X Array like INDEPENDENT VARIABLES \n",
    "    df_harmonized_train[\"Survived\"], # y Array like TARGET or DEPENDENT VARIABLE\n",
    "    cv=20                            # cv=Default = 3 Fold Cross Validation , we used -18 , 20 #>84.75% \n",
    ")                                    # kFold = for n_folds= 22 #>84.40% ,  \n",
    "\n",
    "print(\"{0:.2f}%\".format(scores.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score    # in place of \"cross_validation\" try \"model_selection\" \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Title\", \"Age\",\"Fare\",\"SibSp\", \"Parch\"] #> 84.62%  ---- 7 JAN 17 \n",
    "\n",
    "alg = GradientBoostingClassifier(       # Various parameter values passed :- \n",
    "    \n",
    "    random_state=124,\n",
    "    n_estimators=250,\n",
    "    max_depth=3     \n",
    "                          \n",
    ")\n",
    "\n",
    "                              \n",
    "scores = cross_val_score(\n",
    "    alg,                           # ALGORITHM in Cross_val_score Documentation is called - ESTIMATOR\n",
    "    df_harmonized_train[predictors], # X Array like INDEPENDENT VARIABLES \n",
    "    df_harmonized_train[\"Survived\"], # y Array like TARGET or DEPENDENT VARIABLE\n",
    "    cv=22                            # cv=Default = 3 Fold Cross Validation , we used -18 , 20 #>84.75% \n",
    ")                                    # kFold = for n_folds= 22 #>84.40% ,  \n",
    "\n",
    "print(\"{0:.2f}%\".format(scores.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-4c390af80914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    820\u001b[0m             if (not lib.isscalar(lib.item_from_zerodim(other)) and\n\u001b[1;32m    821\u001b[0m                     len(self) != len(other)):\n\u001b[0;32m--> 822\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lengths must match to compare'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV  \n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Title\", \"Age\",\"Fare\"] #> 84.75%  ---- 7 JAN 17 \n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=124, n_estimators=250, max_depth=3), predictors],\n",
    "    [RandomForestClassifier(random_state=124, n_estimators=250,max_features=2,min_samples_split=6,min_samples_leaf=2), predictors]\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#### Original Code --- Gave Error \n",
    "#### full_predictions_train --- is Not Defined \n",
    "\n",
    "full_predictions = []\n",
    "full_predictions_test = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(xtrain[predictors], ytrain)  ## DHANK -- FIT ON xTRAIN yTRAIN Created above \n",
    "    \n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(df_harmonized_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "    \n",
    "    predictions_test = alg.predict_proba(xtest[predictors].astype(float))[:,1] ## DHANK -PRED ON xTest Created above \n",
    "    full_predictions_test.append(predictions_test)\n",
    "    \n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions <= .5] = 0\n",
    "predictions[predictions > .5] = 1\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "\n",
    "predictions_test = (full_predictions_train[0] * 3 + full_predictions_train[1]) / 4\n",
    "predictions_test[full_predictions_train[0] <= .5] = 0\n",
    "predictions_test[full_predictions_train[0] > .5] = 1\n",
    "#predictions_train = predictions_train.astype(int)\n",
    "accuracy = sum(predictions_test == ytest) / float(len(predictions_train))\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('titanic2.csv', index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#full_predictions = []\\n\\nalg.fit(df_harmonized_train[predictors], df_harmonized_train[\"Survived\"])\\npredictions = alg.predict_proba(df_harmonized_test[predictors].astype(float))[:,1]\\n#full_predictions.append(predictions)\\n\\n#predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\\n\\npredictions[predictions > 0.5] = 1\\npredictions[predictions <= 0.5] = 0\\npredictions = predictions.astype(int)\\n\\nsubmission = pd.DataFrame({\\n        \"PassengerId\": df_harmonized_test[\"PassengerId\"],\\n                               \"Survived\": predictions\\n    })\\nsubmission.to_csv(\\'Submission_Titanic2.csv\\',index=True)\\n\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINAL SUBMISSION - 7th JAN \n",
    "# FINAL SUBMISSION - 7th JAN \n",
    "# FINAL SUBMISSION - 7th JAN \n",
    "# FINAL SUBMISSION - 7th JAN \n",
    "\n",
    "\n",
    "\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "\n",
    "predictors_final = [\"Pclass\", \"Sex\", \"Title\", \"Age\",\"Fare\"] #> 84.75%  ---- 7 JAN 17 \n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 1 , 123 , 124 \n",
    "    n_estimators=350,               # 350 #> 84.74% , 650 #>84.63%    \n",
    "    max_features=2,                 # 2 Dont Change 2 is IDEAL , \n",
    "    min_samples_split=6,            # 4 , 6  # The Deafult Val = 2\n",
    "    min_samples_leaf=2,             # 2 , if 4 #> 83.95%\n",
    "    verbose=0                       # Make it 1 for print in console \n",
    ")\n",
    "\n",
    "\n",
    "#full_predictions = []\n",
    "#for alg, predictors in algorithms:\n",
    "alg.fit(df_harmonized_train[predictors], df_harmonized_train[\"Survived\"])\n",
    "predictions = alg.predict_proba(df_harmonized_test[predictors].astype(float))[:,1]\n",
    "#full_predictions.append(predictions)\n",
    "\n",
    "#predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "\n",
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_harmonized_test[\"PassengerId\"],\n",
    "                               \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('Submission7JAN.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "#full_predictions = []\n",
    "\n",
    "alg.fit(df_harmonized_train[predictors], df_harmonized_train[\"Survived\"])\n",
    "predictions = alg.predict_proba(df_harmonized_test[predictors].astype(float))[:,1]\n",
    "#full_predictions.append(predictions)\n",
    "\n",
    "#predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "\n",
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_harmonized_test[\"PassengerId\"],\n",
    "                               \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('Submission_Titanic2.csv',index=True)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c1399d1faa6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions using the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_harmonized_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \"\"\"\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[1;32m    353\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before exploiting the model."
     ]
    }
   ],
   "source": [
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(df_harmonized_test[predictors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-a339821c22cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m submission = pd.DataFrame({\n\u001b[1;32m      2\u001b[0m         \u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_harmonized_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     })\n\u001b[1;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Titanic_1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_harmonized_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('Titanic_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Title'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-131246b98017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m scores = cross_validation.cross_val_score(\n\u001b[1;32m     16\u001b[0m     \u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf_harmonized_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf_harmonized_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m                            \u001b[0;31m# 18 Nothing else changed ==\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1227\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Title'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Title\", \"Fare\"]\n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 124\n",
    "    n_estimators=250,               # 250 \n",
    "    min_samples_split=6,            # 6  \n",
    "    min_samples_leaf=2              # 2\n",
    ")\n",
    "\n",
    "                                    #> 0.842857142857\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    alg,\n",
    "    df_harmonized_train[predictors],\n",
    "    df_harmonized_train[\"Survived\"],\n",
    "    cv=18                            # 18 Nothing else changed == \n",
    ")\n",
    "\n",
    "print(scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 891, Number of columns: 11\n",
      "__________________________________________________________________________________________\n",
      "             Survived  Pclass  \\\n",
      "PassengerId                     \n",
      "1                   0       3   \n",
      "2                   1       1   \n",
      "3                   1       3   \n",
      "4                   1       1   \n",
      "5                   0       3   \n",
      "\n",
      "                                                          Name     Sex   Age  \\\n",
      "PassengerId                                                                    \n",
      "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
      "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
      "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
      "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
      "5                                     Allen, Mr. William Henry    male  35.0   \n",
      "\n",
      "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "PassengerId                                                          \n",
      "1                1      0         A/5 21171   7.2500   NaN        S  \n",
      "2                1      0          PC 17599  71.2833   C85        C  \n",
      "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "4                1      0            113803  53.1000  C123        S  \n",
      "5                0      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "dft = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "print('Number of rows: {}, Number of columns: {}'.format(*dft.shape))\n",
    "print (\"_\"*90)\n",
    "print(dft.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     1\n",
       "17     0\n",
       "18     1\n",
       "19     0\n",
       "20     1\n",
       "21     0\n",
       "22     1\n",
       "23     1\n",
       "24     1\n",
       "25     0\n",
       "26     1\n",
       "27     0\n",
       "28     0\n",
       "29     1\n",
       "30     0\n",
       "      ..\n",
       "862    0\n",
       "863    1\n",
       "864    0\n",
       "865    0\n",
       "866    1\n",
       "867    1\n",
       "868    0\n",
       "869    0\n",
       "870    1\n",
       "871    0\n",
       "872    1\n",
       "873    0\n",
       "874    0\n",
       "875    1\n",
       "876    1\n",
       "877    0\n",
       "878    0\n",
       "879    0\n",
       "880    1\n",
       "881    1\n",
       "882    0\n",
       "883    0\n",
       "884    0\n",
       "885    0\n",
       "886    0\n",
       "887    0\n",
       "888    1\n",
       "889    0\n",
       "890    1\n",
       "891    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
