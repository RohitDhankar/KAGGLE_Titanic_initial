{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\\n  \"This module will be removed in 0.20.\", DeprecationWarning)\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import operator\n",
    "\n",
    "'''\n",
    "/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
    "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 891, Number of columns: 12\n",
      "__________________________________________________________________________________________\n",
      "Number of rows: 418, Number of columns: 11\n",
      "__________________________________________________________________________________________\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "__________________________________________________________________________________________\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "dfTrn = pd.read_csv(\"train.csv\") # On Local Machine \n",
    "dfTest = pd.read_csv(\"test.csv\") # On Local Machine \n",
    "#dfTrn = pd.read_csv(\"../input/train.csv\") # On Kaggle \n",
    "#dfTest = pd.read_csv(\"../input/test.csv\") # On Kaggle \n",
    "print('Number of rows: {}, Number of columns: {}'.format(*dfTrn.shape))\n",
    "print (\"_\"*90)\n",
    "print('Number of rows: {}, Number of columns: {}'.format(*dfTest.shape))\n",
    "print (\"_\"*90)\n",
    "print(dfTrn.head(5))\n",
    "print (\"_\"*90)\n",
    "print(dfTest.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId = 0\n",
      "Survived = 0\n",
      "Pclass = 0\n",
      "Name = 0\n",
      "Sex = 0\n",
      "Age = 177\n",
      "SibSp = 0\n",
      "Parch = 0\n",
      "Ticket = 0\n",
      "Fare = 0\n",
      "Cabin = 687\n",
      "Embarked = 2\n"
     ]
    }
   ],
   "source": [
    "feature_labels = []\n",
    "missing_values = []\n",
    "\n",
    "for col in dfTrn.columns:\n",
    "    feature_labels.append(col)\n",
    "    missing_values.append(dfTrn[col].isnull().values.ravel().sum()) # Append Feature wise Missing Values  \n",
    "    print(col,\"=\", missing_values[-1]) # prints Feature Labels with Missing Values Count ...\n",
    "\n",
    "#Source - http://stackoverflow.com/questions/28199524/best-way-to-count-the-number-of-rows-with-missing-values-in-a-pandas-dataframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Source - Kaggle - https://www.kaggle.com/michielkalkman/titanic/kaggle-titanic-001\n",
    "\n",
    "# df_Any is any data_set TRAIN or TEST passed to this function\n",
    "\n",
    "def harmonize_data(df_Any):\n",
    "    \n",
    "    df_Any[\"Age\"] = df_Any[\"Age\"].fillna(df_Any[\"Age\"].median()) # Impute missing values\n",
    "#    \n",
    "    df_Any.loc[df_Any[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    df_Any.loc[df_Any[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "#    \n",
    "    df_Any[\"Embarked\"] = df_Any[\"Embarked\"].fillna(\"S\") # Impute missing values\n",
    "#\n",
    "    df_Any.loc[df_Any[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    df_Any.loc[df_Any[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    df_Any.loc[df_Any[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "    df_Any[\"Fare\"] = df_Any[\"Fare\"].fillna(df_Any[\"Fare\"].median())\n",
    "\n",
    "    return df_Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
      "5                                   Moran, Mr. James   0  28.0      0      0   \n",
      "6                            McCarthy, Mr. Timothy J   0  54.0      0      0   \n",
      "7                     Palsson, Master. Gosta Leonard   0   2.0      3      1   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   1  27.0      0      2   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)   1  14.0      1      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        0  \n",
      "1          PC 17599  71.2833   C85        1  \n",
      "2  STON/O2. 3101282   7.9250   NaN        0  \n",
      "3            113803  53.1000  C123        0  \n",
      "4            373450   8.0500   NaN        0  \n",
      "5            330877   8.4583   NaN        2  \n",
      "6             17463  51.8625   E46        0  \n",
      "7            349909  21.0750   NaN        0  \n",
      "8            347742  11.1333   NaN        0  \n",
      "9            237736  30.0708   NaN        1  \n",
      "__________________________________________________________________________________________\n",
      "   PassengerId  Pclass                                          Name Sex  \\\n",
      "0          892       3                              Kelly, Mr. James   0   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)   1   \n",
      "2          894       2                     Myles, Mr. Thomas Francis   0   \n",
      "3          895       3                              Wirz, Mr. Albert   0   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   1   \n",
      "5          897       3                    Svensson, Mr. Johan Cervin   0   \n",
      "6          898       3                          Connolly, Miss. Kate   1   \n",
      "7          899       2                  Caldwell, Mr. Albert Francis   0   \n",
      "8          900       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)   1   \n",
      "9          901       3                       Davies, Mr. John Samuel   0   \n",
      "\n",
      "    Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0     330911   7.8292   NaN        2  \n",
      "1  47.0      1      0     363272   7.0000   NaN        0  \n",
      "2  62.0      0      0     240276   9.6875   NaN        2  \n",
      "3  27.0      0      0     315154   8.6625   NaN        0  \n",
      "4  22.0      1      1    3101298  12.2875   NaN        0  \n",
      "5  14.0      0      0       7538   9.2250   NaN        0  \n",
      "6  30.0      0      0     330972   7.6292   NaN        2  \n",
      "7  26.0      1      1     248738  29.0000   NaN        0  \n",
      "8  18.0      0      0       2657   7.2292   NaN        1  \n",
      "9  21.0      2      0  A/4 48871  24.1500   NaN        0  \n",
      "__________________________________________________________________________________________\n",
      "['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Get Harmonized DF's from Train and Test Data \n",
    "# Cant be running this code cell or function more than once for a particular - df_Any # Test or Train \n",
    "\n",
    "df_harmonized_train = harmonize_data(dfTrn)\n",
    "print(df_harmonized_train.head(10))\n",
    "\n",
    "print (\"_\"*90)\n",
    "df_harmonized_test = harmonize_data(dfTest)\n",
    "print(df_harmonized_test.head(10))\n",
    "\n",
    "names = df_harmonized_test.columns.values\n",
    "print (\"_\"*90)\n",
    "print (names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Source - Kaggle - https://www.kaggle.com/michielkalkman/titanic/kaggle-titanic-001\n",
    "\n",
    "def create_submission(alg, train, test, predictors, filename):\n",
    "\n",
    "    alg.fit(train[predictors], train[\"Survived\"]) # Fit whatever Algorithm passed to \"alg\"\n",
    "    predictions = alg.predict(test[predictors])   # Make predictions on TEST data - dfTest - save \"predictions\" \n",
    "\n",
    "    submission = pd.DataFrame({                   # Create \"submission\" DF ,Two Features- Pid and Preds for SURVIVAL\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(filename, index=False)      # \"Filename\" parameter passed by user - save CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "alg    = LogisticRegression(random_state=1)\n",
    "scores = cross_validation.cross_val_score(\n",
    "    alg,\n",
    "    df_harmonized_train[predictors],\n",
    "    df_harmonized_train[\"Survived\"],\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "print(scores.mean())\n",
    "\n",
    "# Check how \"predictors\" can be \"names\" from above - not to to be typed manually \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835056689342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 1 , 123 , 124\n",
    "    n_estimators=250,               # 150 , 250 , \n",
    "    min_samples_split=6,            # 4 , 6  ##################################\n",
    "    min_samples_leaf=2              # 2 , 2\n",
    ")\n",
    "\n",
    "                                    #> 0.820426487093 #> 0.832833437419 #> 0.83397558283 #> 0.835056689342\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    alg,\n",
    "    df_harmonized_train[predictors],\n",
    "    df_harmonized_train[\"Survived\"],\n",
    "    cv=18                            # 3, 5 , 15, 18 Nothing else changed == 0.835056689342\n",
    ")\n",
    "\n",
    "print(scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"]\n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 124\n",
    "    n_estimators=250,               # 250 \n",
    "    min_samples_split=6,            # 6  \n",
    "    min_samples_leaf=2              # 2\n",
    ")\n",
    "\n",
    "                                    #> 0.842857142857\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    alg,\n",
    "    df_harmonized_train[predictors],\n",
    "    df_harmonized_train[\"Survived\"],\n",
    "    cv=18                            # 18 Nothing else changed == \n",
    ")\n",
    "\n",
    "print(scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\"]\n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 124\n",
    "    n_estimators=250,               # 250 \n",
    "    min_samples_split=6,            # 6  \n",
    "    min_samples_leaf=2              # 2\n",
    ")\n",
    "\n",
    "'''\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=123, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=123), [\"Pclass\", \"Sex\", \"Age\", \"Fare\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    alg.fit(df_harmonized_train[predictors], df_harmonized_train[\"Survived\"])\n",
    "    predictions = alg.predict_proba(df_harmonized_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "\n",
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_harmonized_test[\"PassengerId\"],\n",
    "                               \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('Submission_Titanic.csv',index=True)\n",
    "'''\n",
    "\n",
    "#full_predictions = []\n",
    "\n",
    "alg.fit(df_harmonized_train[predictors], df_harmonized_train[\"Survived\"])\n",
    "predictions = alg.predict_proba(df_harmonized_test[predictors].astype(float))[:,1]\n",
    "#full_predictions.append(predictions)\n",
    "\n",
    "#predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "\n",
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_harmonized_test[\"PassengerId\"],\n",
    "                               \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('Submission_Titanic2.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c1399d1faa6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions using the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_harmonized_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \"\"\"\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[1;32m    353\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before exploiting the model."
     ]
    }
   ],
   "source": [
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(df_harmonized_test[predictors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-a339821c22cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m submission = pd.DataFrame({\n\u001b[1;32m      2\u001b[0m         \u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_harmonized_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     })\n\u001b[1;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Titanic_1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_harmonized_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('Titanic_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Title'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-131246b98017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m scores = cross_validation.cross_val_score(\n\u001b[1;32m     16\u001b[0m     \u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf_harmonized_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf_harmonized_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m                            \u001b[0;31m# 18 Nothing else changed ==\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhankar/anaconda2/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1227\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Title'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Title\", \"Fare\"]\n",
    "\n",
    "alg = RandomForestClassifier(       # Various parameter values passed :- \n",
    "    random_state=124,               # 124\n",
    "    n_estimators=250,               # 250 \n",
    "    min_samples_split=6,            # 6  \n",
    "    min_samples_leaf=2              # 2\n",
    ")\n",
    "\n",
    "                                    #> 0.842857142857\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    alg,\n",
    "    df_harmonized_train[predictors],\n",
    "    df_harmonized_train[\"Survived\"],\n",
    "    cv=18                            # 18 Nothing else changed == \n",
    ")\n",
    "\n",
    "print(scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 891, Number of columns: 11\n",
      "__________________________________________________________________________________________\n",
      "             Survived  Pclass  \\\n",
      "PassengerId                     \n",
      "1                   0       3   \n",
      "2                   1       1   \n",
      "3                   1       3   \n",
      "4                   1       1   \n",
      "5                   0       3   \n",
      "\n",
      "                                                          Name     Sex   Age  \\\n",
      "PassengerId                                                                    \n",
      "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
      "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
      "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
      "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
      "5                                     Allen, Mr. William Henry    male  35.0   \n",
      "\n",
      "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "PassengerId                                                          \n",
      "1                1      0         A/5 21171   7.2500   NaN        S  \n",
      "2                1      0          PC 17599  71.2833   C85        C  \n",
      "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "4                1      0            113803  53.1000  C123        S  \n",
      "5                0      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "dft = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "print('Number of rows: {}, Number of columns: {}'.format(*dft.shape))\n",
    "print (\"_\"*90)\n",
    "print(dft.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     1\n",
       "17     0\n",
       "18     1\n",
       "19     0\n",
       "20     1\n",
       "21     0\n",
       "22     1\n",
       "23     1\n",
       "24     1\n",
       "25     0\n",
       "26     1\n",
       "27     0\n",
       "28     0\n",
       "29     1\n",
       "30     0\n",
       "      ..\n",
       "862    0\n",
       "863    1\n",
       "864    0\n",
       "865    0\n",
       "866    1\n",
       "867    1\n",
       "868    0\n",
       "869    0\n",
       "870    1\n",
       "871    0\n",
       "872    1\n",
       "873    0\n",
       "874    0\n",
       "875    1\n",
       "876    1\n",
       "877    0\n",
       "878    0\n",
       "879    0\n",
       "880    1\n",
       "881    1\n",
       "882    0\n",
       "883    0\n",
       "884    0\n",
       "885    0\n",
       "886    0\n",
       "887    0\n",
       "888    1\n",
       "889    0\n",
       "890    1\n",
       "891    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
